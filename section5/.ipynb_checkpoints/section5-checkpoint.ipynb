{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de522f97",
   "metadata": {},
   "source": [
    "# Section 5 \n",
    "Using the dataset from https://archive.ics.uci.edu/ml/datasets/Car+Evaluation, create a machine learning model to predict the buying price given the following parameters:\n",
    "\n",
    "- Maintenance = High\n",
    "- Number of doors = 4\n",
    "- Lug Boot Size = Big\n",
    "- Safety = High\n",
    "- Class Value = Good\n",
    "\n",
    "# Overall strategy\n",
    "\n",
    "1. Perform exploratory data analysis to see if there are any trends in the data or anomalies that need to be handled\n",
    "2. Handle anomalies and clean data if any\n",
    "3. Use various classification models to perform this multi-class classification task, then select the best performing model to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cd0cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#NN:\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b47323e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "df = pd.read_csv('car.data', names=names, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454a601",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef0a19a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying      object\n",
      "maint       object\n",
      "doors       object\n",
      "persons     object\n",
      "lug_boot    object\n",
      "safety      object\n",
      "class       object\n",
      "dtype: object\n",
      "buying      0\n",
      "maint       0\n",
      "doors       0\n",
      "persons     0\n",
      "lug_boot    0\n",
      "safety      0\n",
      "class       0\n",
      "dtype: int64\n",
      "       buying maint doors persons lug_boot safety  class\n",
      "count    1728  1728  1728    1728     1728   1728   1728\n",
      "unique      4     4     4       3        3      3      4\n",
      "top       med   med     2       2      med    med  unacc\n",
      "freq      432   432   432     576      576    576   1210\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of each column\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics for numerical variables\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4834e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count plot for the target variable\n",
    "sns.countplot(x='buying', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80118f2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS8UlEQVR4nO3df7AdZ33f8fcHiRgCJNjVtSssuzKNSionNj9uNSFOUoKZ2E1S5JIaREqrEjVKJy5xOk2pnE4LUyriTGhTSnAaNQVEoTiqW8cqpDhGxHjsguVr8C/Jdqwix1IlLNm0sd0ENxLf/nFWD0fSveLY1p5zrft+zdzZ3ec8u+d7Z0fno2f37HNTVUiSBPCCSRcgSZo/DAVJUmMoSJIaQ0GS1BgKkqTGUJAkNb2GQpKXJ7kuyQNJ7k/y+iRnJLkpyUPd8vSh/lcl2ZXkwSSX9FmbJOl4fY8UPgh8tqq+F7gQuB/YAGyrqhXAtm6bJCuBNcD5wKXANUkW9VyfJGlI+np4Lcl3AXcDr6yhN0nyIPCGqtqfZClwc1W9KslVAFX1K12/G4H3VtUX53qPJUuW1PLly3upX5JOVXfeeedjVTU122uLe3zfVwIHgY8muRC4E7gSOKuq9gN0wXBm1/9s4EtD++/t2ua0fPlyZmZmTnrhknQqS/JHc73W5+WjxcBrgd+sqtcA/5fuUtEcMkvbccOYJOuTzCSZOXjw4MmpVJIE9BsKe4G9VXV7t30dg5B4tLtsRLc8MNT/nKH9lwH7jj1oVW2qqumqmp6amnX0I0l6lnoLhar6GrAnyau6pouBncBWYG3Xtha4oVvfCqxJclqS84AVwPa+6pMkHa/PewoA7wI+meQ7gK8C72QQRFuSrAMeAS4HqKodSbYwCI5DwBVVdbjn+iRJQ3oNhaq6C5ie5aWL5+i/EdjYZ02SpLn5RLMkqTEUJEmNoSBJagwFSVLT97eP5o3X/eOPT7qEBeHOX/s7vRz3kX/x/b0cV99y7j+/t7djX/Shi3o7tgZue9dtJ+U4jhQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkptdQSPJwknuT3JVkpms7I8lNSR7qlqcP9b8qya4kDya5pM/aJEnHG8dI4Uer6tVVNd1tbwC2VdUKYFu3TZKVwBrgfOBS4Joki8ZQnySpM4nLR6uBzd36ZuCyofZrq+rpqtoN7AJWjb88SVq4+g6FAn4/yZ1J1ndtZ1XVfoBueWbXfjawZ2jfvV2bJGlMFvd8/Iuqal+SM4Gbkjxwgr6Zpa2O6zQIl/UA55577smpUpIE9DxSqKp93fIAcD2Dy0GPJlkK0C0PdN33AucM7b4M2DfLMTdV1XRVTU9NTfVZviQtOL2FQpKXJHnZkXXgx4D7gK3A2q7bWuCGbn0rsCbJaUnOA1YA2/uqT5J0vD4vH50FXJ/kyPv8p6r6bJI7gC1J1gGPAJcDVNWOJFuAncAh4IqqOtxjfZKkY/QWClX1VeDCWdofBy6eY5+NwMa+apIknZhPNEuSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkpvdQSLIoyVeSfLrbPiPJTUke6panD/W9KsmuJA8muaTv2iRJRxvHSOFK4P6h7Q3AtqpaAWzrtkmyElgDnA9cClyTZNEY6pMkdXoNhSTLgJ8AfnuoeTWwuVvfDFw21H5tVT1dVbuBXcCqPuuTJB2t75HCvwHeDXxzqO2sqtoP0C3P7NrPBvYM9dvbtUmSxqS3UEjyk8CBqrpz1F1maatZjrs+yUySmYMHDz6nGiVJR+tzpHAR8OYkDwPXAm9M8gng0SRLAbrlga7/XuCcof2XAfuOPWhVbaqq6aqanpqa6rF8SVp4eguFqrqqqpZV1XIGN5A/X1XvALYCa7tua4EbuvWtwJokpyU5D1gBbO+rPknS8RZP4D2vBrYkWQc8AlwOUFU7kmwBdgKHgCuq6vAE6pOkBWssoVBVNwM3d+uPAxfP0W8jsHEcNUmSjucTzZKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1I4VCkm2jtEmSnt9O+Deak7wI+E5gSZLTgXQvfRfwip5rkySN2QlDAfg54BcZBMCdfCsUngA+3F9ZkqRJOGEoVNUHgQ8meVdVfWhMNUmSJuTbjRQAqKoPJflBYPnwPlX18Z7qkiRNwEihkOQ/An8RuAs43DUXYChI0ilkpFAApoGVVVV9FiNJmqxRn1O4D/jzfRYiSZq8UUcKS4CdSbYDTx9prKo391KVJGkiRg2F9z7TA3fPONwCnNa9z3VV9Z4kZwC/w+Cm9cPAW6vqf3f7XAWsY3Df4heq6sZn+r6SpGdv1G8ffeFZHPtp4I1V9VSSFwK3JvnvwFuAbVV1dZINwAbgnyRZCawBzmfwXMTnkvylqjo81xtIkk6uUae5eDLJE93PN5IcTvLEifapgae6zRd2PwWsBjZ37ZuBy7r11cC1VfV0Ve0GdgGrntmvI0l6LkYdKbxseDvJZYzwgZ1kEYMnob8H+HBV3Z7krKra3x13f5Izu+5nA18a2n1v1yZJGpNnNUtqVf0u8MYR+h2uqlcDy4BVSb7vBN0zS9txX4FNsj7JTJKZgwcPjlixJGkUoz689pahzRcweG5h5GcWqur/JLkZuBR4NMnSbpSwFDjQddsLnDO02zJg3yzH2gRsApienva5CUk6iUYdKfz1oZ9LgCcZ3AOYU5KpJC/v1l8MvAl4ANgKrO26rQVu6Na3AmuSnJbkPGAFsH3k30SS9JyNek/hnc/i2EuBzd19hRcAW6rq00m+CGxJsg54BLi8e48dSbYAO4FDwBV+80iSxmvUy0fLgA8BFzG4bHQrcGVV7Z1rn6q6B3jNLO2PAxfPsc9GYOMoNUmSTr5RLx99lMHlnVcw+EbQf+vaJEmnkFFDYaqqPlpVh7qfjwFTPdYlSZqAUUPhsSTvSLKo+3kH8HifhUmSxm/UUPgZ4K3A14D9wN8Ens3NZ0nSPDbqhHjvA9YOTVx3BvABBmEhSTpFjDpSuOBIIABU1deZ5ZtFkqTnt1FD4QVJTj+y0Y0URh1lSJKeJ0b9YP9XwP9Ich2D5xTeis8TSNIpZ9Qnmj+eZIbBJHgB3lJVO3utTJI0diNfAupCwCCQpFPYs5o6W5J0ajIUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKnpLRSSnJPkD5Lcn2RHkiu79jOS3JTkoW55+tA+VyXZleTBJJf0VZskaXZ9jhQOAf+oqv4y8APAFUlWAhuAbVW1AtjWbdO9tgY4H7gUuCbJoh7rkyQdo7dQqKr9VfXlbv1J4H7gbGA1sLnrthm4rFtfDVxbVU9X1W5gF7Cqr/okSccbyz2FJMuB1wC3A2dV1X4YBAdwZtftbGDP0G57uzZJ0pj0HgpJXgr8F+AXq+qJE3Wdpa1mOd76JDNJZg4ePHiyypQk0XMoJHkhg0D4ZFX916750SRLu9eXAge69r3AOUO7LwP2HXvMqtpUVdNVNT01NdVf8ZK0APX57aMA/wG4v6r+9dBLW4G13fpa4Iah9jVJTktyHrAC2N5XfZKk4y3u8dgXAX8buDfJXV3bLwNXA1uSrAMeAS4HqKodSbYAOxl8c+mKqjrcY32SpGP0FgpVdSuz3ycAuHiOfTYCG/uqSZJ0Yj7RLElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJKa3kIhyUeSHEhy31DbGUluSvJQtzx96LWrkuxK8mCSS/qqS5I0tz5HCh8DLj2mbQOwrapWANu6bZKsBNYA53f7XJNkUY+1SZJm0VsoVNUtwNePaV4NbO7WNwOXDbVfW1VPV9VuYBewqq/aJEmzG/c9hbOqaj9Atzyzaz8b2DPUb2/XJkkao/lyozmztNWsHZP1SWaSzBw8eLDnsiRpYRl3KDyaZClAtzzQte8FzhnqtwzYN9sBqmpTVU1X1fTU1FSvxUrSQjPuUNgKrO3W1wI3DLWvSXJakvOAFcD2MdcmSQve4r4OnORTwBuAJUn2Au8Brga2JFkHPAJcDlBVO5JsAXYCh4ArqupwX7VJkmbXWyhU1dvneOniOfpvBDb2VY8k6dubLzeaJUnzgKEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSM+9CIcmlSR5MsivJhknXI0kLybwKhSSLgA8Dfw1YCbw9ycrJViVJC8e8CgVgFbCrqr5aVf8PuBZYPeGaJGnBmG+hcDawZ2h7b9cmSRqDxZMu4BiZpa2O6pCsB9Z3m08lebD3qiZnCfDYpIt4JvKBtZMuYT55fp2/98z2z2/Ben6dOyC/8IzO31+Y64X5Fgp7gXOGtpcB+4Y7VNUmYNM4i5qUJDNVNT3pOvTseP6evxbyuZtvl4/uAFYkOS/JdwBrgK0TrkmSFox5NVKoqkNJ/gFwI7AI+EhV7ZhwWZK0YMyrUACoqt8Dfm/SdcwTC+Iy2SnM8/f8tWDPXarq2/eSJC0I8+2egiRpggyF57EkT3XL5Unum3Q9euaS3JxkQX7LZdLm+neT5LcX8kwK8+6egiRNUlX9vUnXMEmOFMYkyUuSfCbJ3UnuS/K2JA8neX+SLyaZSfLaJDcm+Z9J/n6330uTbEvy5ST3JnHajwnr/of5QPc/yvuSfDLJm5LcluShJKu68/2RJHck+cqR85bkxUmuTXJPkt8BXjzhX2ehW5xkc3c+rkvyncOjtyTrkvxh1/bvk/zGpAvumyOF8bkU2FdVPwGQ5LuBXwX2VNXrk/w68DHgIuBFwA7g3wHfAP5GVT2RZAnwpSRby28ITNr3AJczeLr+DuCngR8C3gz8MrAT+HxV/UySlwPbk3wO+DngT6rqgiQXAF+eRPFqXgWsq6rbknwE+PkjLyR5BfDPgNcCTwKfB+6eSJVj5EhhfO4F3pTkV5P8cFX9cde+dej126vqyao6CHyj+zAJ8P4k9wCfYzAX1Fljrl3H211V91bVNxkE+LYuqO8FlgM/BmxIchdwM4OgPxf4EeATAFV1D3DP2CvXsD1VdVu3/gkGwX7EKuALVfX1qvoz4D+PvboJcKQwJlX1h0leB/w48CtJfr976elu+c2h9SPbi4G/BUwBr6uqP0vyMIMPGE3Wsedq+DwuBg4DP1VVR83NlQSOmc9LE3XsuRjeXpCTQTlSGJNuKPonVfUJ4AMMhqSj+G7gQBcIP8oJJrLSvHIj8K50KZDkNV37LQyCniTfB1wwmfLUOTfJ67v1twO3Dr22HfirSU5Pshj4qbFXNwGGwvh8P4PryncB/xT4lyPu90lgOskMgw+TB/opTyfZ+4AXAvd0X3t8X9f+m8BLu8uB72bwwaPJuR9Y252PMxicHwCq6n8B7wduZ3Dpdifwx7Md5FTiE82SNIckL62qp7qRwvUM5mO7ftJ19cmRgiTN7b3d6P4+YDfwuxOtZgwcKUiSGkcKkqTGUJAkNYaCJKkxFCRJjaEg8a1pyE/i8d6b5JdOwnGWJ/npk1GTNApDQZrfljOYbE8aC0NBGpLkDUk+PbT9G0n+brf+492U2bcm+bfD/eZwYZLPd9Np/2x3jCT5tW7K7XuTvO1E7cDVwA8nuSvJPzz5v7F0NCfEk0aQ5EXAbwE/UlW7k3xqhN0uAH4AeAnwlSSfAV4PvBq4EFgC3JHkFuAH52jfAPxSVf3kyf2NpNk5UpBG873AV6tqd7c9SijcUFV/WlWPAX/AYCrmHwI+VVWHq+pR4AvAXzlBuzRWhoJ0tEMc/e/iyDTlz2Ya5dmmZZ7rOAtymmbNP4aCdLQ/AlYmOa3763gXd+0PAK9MsrzbfttsOx9jdZIXJflzwBsY/IW2W4C3JVmUZIrBH93ZfoL2J4GXnZxfTfr2vKcgDamqPUm2MPiLaA8BX+na/zTJzwOfTfIYo015vR34DIO/uPa+qtqX5HoG9xXuZjByeHdVfe0E7Y8Dh5LcDXysqn79pP7C0jGcEE8a0dA0ygE+DDzkh7RONV4+kkb3s900yjsY/EW835psOdLJ50hBeg6SvBO48pjm26rqiknUIz1XhoIkqfHykSSpMRQkSY2hIElqDAVJUmMoSJKa/w9ANAYRphi5vQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUuUlEQVR4nO3df7DddX3n8eeLICACAnJBTNgmtdEuUFtrhmWlq1ScIW2tYS04cRbJKttsuyi1U7eCu61ubWboYLtVVtzNWiFYK42ohbKtipkCq/LDyy8hIJIRhUiEi1KkWtHge//4frMcw00+l5t7z7mX+3zMnDnnvM/ne877fOfkvvL9fs/3c1JVSJK0O3uNugFJ0txnWEiSmgwLSVKTYSFJajIsJElNe4+6gdly2GGH1dKlS0fdhiTNKzfddNPDVTW2c/0ZGxZLly5lfHx81G1I0ryS5BuT1d0NJUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmmYtLJJ8OMlDSe4YqJ2f5CtJvpzkU0kOHnjs3CRbktyd5OSB+suS3N4/9v4kma2eJUmTm80ti4uBlTvVrgKOraqXAF8FzgVIcjSwGjimX+bCJIv6ZT4IrAWW95edn1OSNMtm7Qzuqro2ydKdap8duHs9cGp/exVwaVU9DtybZAtwXJKvAwdV1XUASS4BTgH+fk/7e9l/vmRPn+IZ46bzzxh1C5LmuFEes3gzT/7RXwzcP/DY1r62uL+9c31SSdYmGU8yPjExMcPtStLCNZKwSPJfgO3AR3eUJhlWu6lPqqrWV9WKqloxNvaUebAkSdM09IkEk6wBXgOcVE/+APhW4KiBYUuAB/r6kknqkqQhGuqWRZKVwDuA11bV9wceugJYnWTfJMvoDmTfWFXbgMeSHN9/C+oM4PJh9ixJmsUtiyQfA04EDkuyFXgX3bef9gWu6r8Be31V/VZVbU6yEbiTbvfUWVX1RP9Uv033zapn0x3j2OOD25Kkp2c2vw31hknKf7Gb8euAdZPUx4FjZ7A1SdLT5BnckqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqSmWQuLJB9O8lCSOwZqhya5Ksk9/fUhA4+dm2RLkruTnDxQf1mS2/vH3p8ks9WzJGlys7llcTGwcqfaOcCmqloObOrvk+RoYDVwTL/MhUkW9ct8EFgLLO8vOz+nJGmWzVpYVNW1wHd2Kq8CNvS3NwCnDNQvrarHq+peYAtwXJIjgYOq6rqqKuCSgWUkSUMy7GMWR1TVNoD++vC+vhi4f2Dc1r62uL+9c12SNERz5QD3ZMchajf1yZ8kWZtkPMn4xMTEjDUnSQvdsMPiwX7XEv31Q319K3DUwLglwAN9fckk9UlV1fqqWlFVK8bGxma0cUlayIYdFlcAa/rba4DLB+qrk+ybZBndgewb+11VjyU5vv8W1BkDy0iShmTv2XriJB8DTgQOS7IVeBdwHrAxyZnAfcBpAFW1OclG4E5gO3BWVT3RP9Vv032z6tnA3/cXSdIQzVpYVNUbdvHQSbsYvw5YN0l9HDh2BluTJD1Nc+UAtyRpDjMsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNIwmLJL+bZHOSO5J8LMl+SQ5NclWSe/rrQwbGn5tkS5K7k5w8ip4laSEbelgkWQycDayoqmOBRcBq4BxgU1UtBzb190lydP/4McBK4MIki4bdtyQtZKPaDbU38OwkewP7Aw8Aq4AN/eMbgFP626uAS6vq8aq6F9gCHDfcdiVpYRt6WFTVN4H3AvcB24BHq+qzwBFVta0fsw04vF9kMXD/wFNs7WtPkWRtkvEk4xMTE7P1FiRpwRnFbqhD6LYWlgEvAJ6T5PTdLTJJrSYbWFXrq2pFVa0YGxvb82YlScBodkO9Gri3qiaq6kfAJ4GXAw8mORKgv36oH78VOGpg+SV0u60kSUMyirC4Dzg+yf5JApwE3AVcAazpx6wBLu9vXwGsTrJvkmXAcuDGIfcsSQva3sN+waq6IcllwM3AduAWYD1wALAxyZl0gXJaP35zko3Anf34s6rqiWH3LUkL2dDDAqCq3gW8a6fy43RbGZONXwesm+2+JEmT8wxuSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTVMKiySbplKTJD0z7XYiwST70f3s6WH9jxbt+CGig+h+uEiStAC0Zp39j8Db6ILhJp4Mi+8CH5i9tiRJc8luw6Kq3ge8L8lbq+qCIfUkSZpjpvR7FlV1QZKXA0sHl6mqS2apL0nSHDKlsEjyEeCFwK3Ajl+pK8CwkKQFYKq/lLcCOLqqajabkSTNTVM9z+IO4Pmz2Ygkae6a6pbFYcCdSW6k+61sAKrqtbPSlSRpTplqWLx7NpuQJM1tU/021DWz3Ygkae6a6rehHqP79hPAPsCzgO9V1UGz1Zgkae6Y6pbFgYP3k5wCHDcbDUmS5p5pzTpbVX8DvGpmW5EkzVVT3Q31uoG7e9GddzHtcy6SHAx8CDi2f543A3cDf013lvjXgddX1SP9+HOBM+lOCDy7qj4z3deWJD19U/021K8P3N5O98d81R687vuAT1fVqUn2oZvZ9p3Apqo6L8k5wDnAO5IcDawGjqGb0PBzSV5UVU/s6sklSTNrqscs3jRTL5jkIOAVwL/vn/uHwA+TrAJO7IdtAK4G3kEXSpdW1ePAvUm20B0vuW6mepIk7d5Uf/xoSZJPJXkoyYNJPpFkyTRf86eBCeCiJLck+VCS5wBHVNU2gP768H78YuD+geW39rXJ+lybZDzJ+MTExDTbkyTtbKoHuC8CrqDbDbQY+Nu+Nh17A78IfLCqXgp8j26X065kktqkx0uqan1VraiqFWNjY9NsT5K0s6mGxVhVXVRV2/vLxcB0/xpvBbZW1Q39/cvowuPBJEcC9NcPDYw/amD5JcAD03xtSdI0TDUsHk5yepJF/eV04NvTecGq+hZwf5IX96WTgDvptlzW9LU1wOX97SuA1Un2TbIMWA7cOJ3XliRNz1S/DfVm4H8A/51uF9AXgT056P1W4KP9N6G+1j/XXsDGJGcC9wGnAVTV5iQb6QJlO3CW34SSpOGaali8B1gzcN7DocB76ULkaauqW+nO1djZSbsYvw5YN53XkiTtuanuhnrJjqAAqKrvAC+dnZYkSXPNVMNirySH7LjTb1lMdatEkjTPTfUP/p8CX0xyGd0xi9fjbiFJWjCmegb3JUnG6SYPDPC6qrpzVjuTJM0ZU96V1IeDASFJC9C0piiXJC0shoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkppGFRZJFSW5JcmV//9AkVyW5p78+ZGDsuUm2JLk7ycmj6lmSFqpRbln8DnDXwP1zgE1VtRzY1N8nydHAauAYYCVwYZJFQ+5Vkha0kYRFkiXArwEfGiivAjb0tzcApwzUL62qx6vqXmALcNyQWpUkMbotiz8Hfh/48UDtiKraBtBfH97XFwP3D4zb2teeIsnaJONJxicmJma8aUlaqIYeFkleAzxUVTdNdZFJajXZwKpaX1UrqmrF2NjYtHuUJP2kvUfwmicAr03yq8B+wEFJ/hJ4MMmRVbUtyZHAQ/34rcBRA8svAR4YaseStMANPSyq6lzgXIAkJwJvr6rTk5wPrAHO668v7xe5AvirJH8GvABYDtw45LbVcN8f/dyoW5gz/sUf3j7qFqQZN4oti105D9iY5EzgPuA0gKranGQjcCewHTirqp4YXZuStPCMNCyq6mrg6v72t4GTdjFuHbBuaI1Jkn6CZ3BLkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpqGHhZJjkryD0nuSrI5ye/09UOTXJXknv76kIFlzk2yJcndSU4eds+StNCNYstiO/B7VfUvgeOBs5IcDZwDbKqq5cCm/j79Y6uBY4CVwIVJFo2gb0lasIYeFlW1rapu7m8/BtwFLAZWARv6YRuAU/rbq4BLq+rxqroX2AIcN9SmJWmBG+kxiyRLgZcCNwBHVNU26AIFOLwfthi4f2CxrX1NkjQkIwuLJAcAnwDeVlXf3d3QSWq1i+dcm2Q8yfjExMRMtClJYkRhkeRZdEHx0ar6ZF9+MMmR/eNHAg/19a3AUQOLLwEemOx5q2p9Va2oqhVjY2Oz07wkLUCj+DZUgL8A7qqqPxt46ApgTX97DXD5QH11kn2TLAOWAzcOq19JEuw9gtc8AXgjcHuSW/vaO4HzgI1JzgTuA04DqKrNSTYCd9J9k+qsqnpi6F1L0gI29LCoqs8z+XEIgJN2scw6YN2sNSVJ2i3P4JYkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1jeJnVSVpaK55xStH3cKc8cprr5n2soaFNMeccMEJo25hzvjCW78w6hbUczeUJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqmjdhkWRlkruTbElyzqj7kaSFZF6ERZJFwAeAXwGOBt6Q5OjRdiVJC8e8CAvgOGBLVX2tqn4IXAqsGnFPkrRgpKpG3UNTklOBlVX1H/r7bwT+VVW9Zadxa4G1/d0XA3cPtdHpOQx4eNRNPEO4LmeW63NmzZf1+VNVNbZzcb7MDZVJak9JuapaD6yf/XZmTpLxqlox6j6eCVyXM8v1ObPm+/qcL7uhtgJHDdxfAjwwol4kacGZL2HxJWB5kmVJ9gFWA1eMuCdJWjDmxW6oqtqe5C3AZ4BFwIeravOI25op82q32RznupxZrs+ZNa/X57w4wC1JGq35shtKkjRChoUkqcmwkDQjkpyY5MpR9zGfJVma5I5R9zEZw0KS1GRYzICd/zeQ5O1J3p3k6iR/kuTGJF9N8m8Gxv/fJDf3l5cPLPv7SW5PcluS8/razyT5XF+7OckLh/8u54Ykf5PkpiSb+zP2d0wyeXO/fjb1tQOSXNSvyy8n+Y3Rdj4a/efvPw3cf3eS30tyYb8Or0zyd/0sCSQ5Kckt/Xr7cJJ9G/WVSb6S5PPA60byJkcoyR/07/+qJB/r/+3/QpLr+8/dp5Ic0o/dVf1l/Wf3OuCskb6h3akqL3t4AZYCdwzcfzvwbuBq4E/72q8Cn+tv7w/s199eDoz3t38F+CKwf3//0P76BuDf9rf32/H4QrwMrJNnA3cARwD3A8t2evxPgD8fWO6QUfc+ovX1UuCagft3AmcAf0f3n8XnA48Ap/afrfuBF/VjLwHeNoX6crpZFjYCV476PQ9x3a4Abu0/iwcC9/T/9r8MvLIf80c7PodTrJ8/+LdkLl3csph9n+yvb6ILFYBnAf87ye3Ax+lm0gV4NXBRVX0foKq+k+RAYHFVfaqv/WDH4wvU2UluA66nO6t/LXBtVd0L3Trrx72abqZi+vojw250LqiqW4DDk7wgyc/TBcMvAh+vqh9X1beAf+iHvxi4t6q+2t/fALxiN/Wf7ev3VPeX7i+H867mjF8CLq+qf66qx4C/BZ4DHFxV1/RjNgCvSPLcKdY/MsT+n5Z5cVLePLCdn9ylt9/A7cf76yd4cn3/LvAg8PP9cj/o6+Gpc15NNi/WgpTkRLoQ+NdV9f0kVwO30f0xe8pwJpk/bIG6jG7L4fl0Mzb/zC7G7eqztrvP4EJexzPxb3PefE7dspgZD9L97+15/b7c1zTGPxfYVlU/Bt5Id1Y6wGeBNyfZHyDJoVX1XWBrklP62r47Hl+Angs80gfFzwLHA/sCr0yyDLp11o/9LPD/ZyXesX94gbqUboqcU+mC4/PAbyTZK8kRwIn9uK8AS5PsCJM3Atc06ssGjqG9YbbfyBzzeeDXk+yX5ADg14DvAY/sOD5Jv66q6tFd1P8ReDTJL/X1fze89p8ew2IGVNWP6PZB3gBcSfePaHcuBNYkuR54Ed0HjKr6NN2cV+NJbqXb/wndB+vsJF+mO6bx/Jl+D/PEp4G9+/XwHrpdURN0u6I+2e+e+ut+7B8DhyS5o6//8iganguqmxrnQOCbVbUN+ATd5Jx3AP+L7nP7aFX9AHgT8PF+F+mPgf/ZqK8F/k9/gPsbQ35rI1VVX6L793ob3e7mceBRYA1wfv85/QW6vw3spv4m4AP9Ae5/Hlb/T5fTfUgLUJIDquqfkjwPuBE4oT9+oadhYD3uD1wLrK2qm0fd12zwmIW0MF2Z5GBgH+A9BsW0rU/3E8/7ARueqUEBbllIkqbAYxaSpCbDQpLUZFhIkpoMC2kW9HMwvb09UpofDAtJUpNhIc2AJGf0s4neluQjOz32m0m+1D/2iYEz9E/bcdJgkmv72jHpZim+tX++5aN4P9LO/OqstIeSHEN3Bu8JVfVwP+XI2cA/VdV7kzyvqr7dj/1j4MGquqA/G3plVX0zycFV9Y9JLgCur6qPJtkHWFRVc/asXi0cbllIe+5VwGVV9TD8xMy3Oxyb7vdLbqeb++eYvv4F4OIkv8mT84NdB7wzyTuAnzIoNFcYFtKea80cejHwlqr6OeC/0c9KXFW/BfxXuqnWb+23QP4KeC3dHEGfSfKq2WxcmirDQtpzm4DX9/MsDc58u8OBwLYkz2JgVtEkL6yqG6rqD4GHgaOS/DTwtap6P90kdS8ZyjuQGpwbStpDVbU5yTrgmiRPALcAXx8Y8gd0M7t+A7idLjygm4F0x6/MbaKbvfQc4PQkPwK+xZMzk0oj5QFuSVKTu6EkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVLT/wO8AExpxZdBkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count plot for each categorical variable\n",
    "sns.countplot(x='maint', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='doors', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='persons', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='lug_boot', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='safety', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99db906b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying  high  low  med  vhigh\n",
       "maint                        \n",
       "high     108  108  108    108\n",
       "low      108  108  108    108\n",
       "med      108  108  108    108\n",
       "vhigh    108  108  108    108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5more</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying  high  low  med  vhigh\n",
       "doors                        \n",
       "2        108  108  108    108\n",
       "3        108  108  108    108\n",
       "4        108  108  108    108\n",
       "5more    108  108  108    108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persons</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying   high  low  med  vhigh\n",
       "persons                       \n",
       "2         144  144  144    144\n",
       "4         144  144  144    144\n",
       "more      144  144  144    144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lug_boot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying    high  low  med  vhigh\n",
       "lug_boot                       \n",
       "big        144  144  144    144\n",
       "med        144  144  144    144\n",
       "small      144  144  144    144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying  high  low  med  vhigh\n",
       "safety                       \n",
       "high     144  144  144    144\n",
       "low      144  144  144    144\n",
       "med      144  144  144    144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.crosstab(df['maint'], df['buying']))\n",
    "display(pd.crosstab(df['doors'], df['buying']))\n",
    "display(pd.crosstab(df['persons'], df['buying']))\n",
    "display(pd.crosstab(df['lug_boot'], df['buying']))\n",
    "display(pd.crosstab(df['safety'], df['buying']))\n",
    "\n",
    "# no relation at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c75d4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>doors</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5more</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persons</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "doors      2    3    4  5more\n",
       "persons                      \n",
       "2        144  144  144    144\n",
       "4        144  144  144    144\n",
       "more     144  144  144    144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.crosstab(df['persons'], df['doors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bef1e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>108</td>\n",
       "      <td>89</td>\n",
       "      <td>115</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>324</td>\n",
       "      <td>258</td>\n",
       "      <td>268</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying  high  low  med  vhigh\n",
       "class                        \n",
       "acc      108   89  115     72\n",
       "good       0   46   23      0\n",
       "unacc    324  258  268    360\n",
       "vgood      0   39   26      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>buying</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>med</th>\n",
       "      <th>vhigh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.206019</td>\n",
       "      <td>0.266204</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.053241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090278</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "buying  high       low       med     vhigh\n",
       "class                                     \n",
       "acc     0.25  0.206019  0.266204  0.166667\n",
       "good    0.00  0.106481  0.053241  0.000000\n",
       "unacc   0.75  0.597222  0.620370  0.833333\n",
       "vgood   0.00  0.090278  0.060185  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.crosstab(df['class'], df['buying']))\n",
    "display(pd.crosstab(df['class'], df['buying'], normalize='columns'))\n",
    "\n",
    "# in general, lower buying price means that the car is more acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb61622",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4f058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_classification(X_train, y_train):\n",
    "    \"\"\"Perform a grid search to find the best multi-class classification model and hyperparameters using f1 score.\"\"\"\n",
    "    \n",
    "    # Define the classifiers to be tested\n",
    "    classifiers = {'Decision Tree': DecisionTreeClassifier(),\n",
    "                   'Random Forest': RandomForestClassifier(),\n",
    "                   'Naive Bayes': GaussianNB(),\n",
    "                   'SVC': SVC()}\n",
    "    \n",
    "    # Define the hyperparameters to be tested for each classifier\n",
    "    param_grids = {'Decision Tree': {'max_depth': [3, 5, 7]},\n",
    "                   'Random Forest': {'n_estimators': [50, 100, 150],\n",
    "                                     'max_depth': [3, 5, 7]},\n",
    "                   'Naive Bayes': {},\n",
    "                   'SVC': {'C': [0.1, 1, 10],\n",
    "                           'kernel': ['linear', 'rbf']}}\n",
    "    \n",
    "    # Perform a grid search for each classifier\n",
    "    results = {}\n",
    "    for name, classifier in classifiers.items():\n",
    "        param_grid = param_grids[name]\n",
    "        grid_search = GridSearchCV(estimator=classifier,\n",
    "                                   param_grid=param_grid,\n",
    "                                   cv=5,\n",
    "                                   scoring='f1_macro')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        results[name] = {'best_params': grid_search.best_params_,\n",
    "                         'best_score': grid_search.best_score_,\n",
    "                         'best_estimator': grid_search.best_estimator_}\n",
    "    \n",
    "    # Print the results\n",
    "    for name, result in results.items():\n",
    "        print(f\"{name}: Best parameters: {result['best_params']}\")\n",
    "        print(f\"{name}: Best f1 score: {result['best_score']}\")\n",
    "    \n",
    "    # Return the best model found\n",
    "    best_model_name = max(results, key=lambda k: results[k]['best_score'])\n",
    "    best_model = results[best_model_name]['best_estimator']\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93b5f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using one-hot encoding\n",
    "X_cols = ['maint','doors','persons','lug_boot','safety','class']\n",
    "y = df['buying']\n",
    "X = pd.get_dummies(df[X_cols],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c70c7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Best parameters: {'max_depth': 5}\n",
      "Decision Tree: Best f1 score: 0.28602930549430167\n",
      "Random Forest: Best parameters: {'max_depth': 3, 'n_estimators': 150}\n",
      "Random Forest: Best f1 score: 0.27377407847010615\n",
      "Naive Bayes: Best parameters: {}\n",
      "Naive Bayes: Best f1 score: 0.2464534372005625\n",
      "SVC: Best parameters: {'C': 10, 'kernel': 'linear'}\n",
      "SVC: Best f1 score: 0.3252433634263832\n",
      "Best model: SVC\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Gridsearch for the best multiclass classification model \n",
    "best_model_cat = gridsearch_classification(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49f362be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is 0.33260484322466016\n",
      "accuracy is 0.332\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_cat.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'f1 score is {f1}')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy is {round(accuracy,3)}') #given that this is a balanced dataset with 4 categories, baseline accuracy is 0.25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe2e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2ca0d09",
   "metadata": {},
   "source": [
    "# Modeling - neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96b1d384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 1.4279 - accuracy: 0.2357 - val_loss: 1.4052 - val_accuracy: 0.2446\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3894 - accuracy: 0.2462 - val_loss: 1.3975 - val_accuracy: 0.2086\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3809 - accuracy: 0.2703 - val_loss: 1.3916 - val_accuracy: 0.2230\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3752 - accuracy: 0.2872 - val_loss: 1.3927 - val_accuracy: 0.2230\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3717 - accuracy: 0.2776 - val_loss: 1.3890 - val_accuracy: 0.2302\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3684 - accuracy: 0.2969 - val_loss: 1.3902 - val_accuracy: 0.2518\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3657 - accuracy: 0.2944 - val_loss: 1.3869 - val_accuracy: 0.2302\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3628 - accuracy: 0.3146 - val_loss: 1.3836 - val_accuracy: 0.2518\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3604 - accuracy: 0.3146 - val_loss: 1.3825 - val_accuracy: 0.2590\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3574 - accuracy: 0.3186 - val_loss: 1.3770 - val_accuracy: 0.2518\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3508 - accuracy: 0.3298 - val_loss: 1.3750 - val_accuracy: 0.2158\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3500 - accuracy: 0.3250 - val_loss: 1.3741 - val_accuracy: 0.2590\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3474 - accuracy: 0.3202 - val_loss: 1.3738 - val_accuracy: 0.2302\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3440 - accuracy: 0.3298 - val_loss: 1.3656 - val_accuracy: 0.2230\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3376 - accuracy: 0.3403 - val_loss: 1.3723 - val_accuracy: 0.2446\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3371 - accuracy: 0.3355 - val_loss: 1.3753 - val_accuracy: 0.2374\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3322 - accuracy: 0.3282 - val_loss: 1.3620 - val_accuracy: 0.2230\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3265 - accuracy: 0.3492 - val_loss: 1.3642 - val_accuracy: 0.2302\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3251 - accuracy: 0.3347 - val_loss: 1.3545 - val_accuracy: 0.2158\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3215 - accuracy: 0.3266 - val_loss: 1.3590 - val_accuracy: 0.2230\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3174 - accuracy: 0.3484 - val_loss: 1.3411 - val_accuracy: 0.2230\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3160 - accuracy: 0.3435 - val_loss: 1.3398 - val_accuracy: 0.2230\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3100 - accuracy: 0.3355 - val_loss: 1.3356 - val_accuracy: 0.2662\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3092 - accuracy: 0.3516 - val_loss: 1.3361 - val_accuracy: 0.2518\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3028 - accuracy: 0.3685 - val_loss: 1.3309 - val_accuracy: 0.2662\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3002 - accuracy: 0.3371 - val_loss: 1.3428 - val_accuracy: 0.2374\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2960 - accuracy: 0.3500 - val_loss: 1.3243 - val_accuracy: 0.2302\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2948 - accuracy: 0.3419 - val_loss: 1.3258 - val_accuracy: 0.2518\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2932 - accuracy: 0.3484 - val_loss: 1.3435 - val_accuracy: 0.2446\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2890 - accuracy: 0.3572 - val_loss: 1.3318 - val_accuracy: 0.2806\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2859 - accuracy: 0.3604 - val_loss: 1.3274 - val_accuracy: 0.2374\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2828 - accuracy: 0.3540 - val_loss: 1.3335 - val_accuracy: 0.2374\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2804 - accuracy: 0.3548 - val_loss: 1.3238 - val_accuracy: 0.2374\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2794 - accuracy: 0.3435 - val_loss: 1.3225 - val_accuracy: 0.2158\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2770 - accuracy: 0.3628 - val_loss: 1.3211 - val_accuracy: 0.2374\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2789 - accuracy: 0.3636 - val_loss: 1.3285 - val_accuracy: 0.2662\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2712 - accuracy: 0.3669 - val_loss: 1.3518 - val_accuracy: 0.2734\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2710 - accuracy: 0.3669 - val_loss: 1.3185 - val_accuracy: 0.2446\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2665 - accuracy: 0.3612 - val_loss: 1.3141 - val_accuracy: 0.2374\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2654 - accuracy: 0.3612 - val_loss: 1.3071 - val_accuracy: 0.2590\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2676 - accuracy: 0.3660 - val_loss: 1.3162 - val_accuracy: 0.2518\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2676 - accuracy: 0.3540 - val_loss: 1.3245 - val_accuracy: 0.2446\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2629 - accuracy: 0.3669 - val_loss: 1.3295 - val_accuracy: 0.2302\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2612 - accuracy: 0.3725 - val_loss: 1.3025 - val_accuracy: 0.2302\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2592 - accuracy: 0.3781 - val_loss: 1.3196 - val_accuracy: 0.2878\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2575 - accuracy: 0.3620 - val_loss: 1.3172 - val_accuracy: 0.2878\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2537 - accuracy: 0.3765 - val_loss: 1.3136 - val_accuracy: 0.2590\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2532 - accuracy: 0.3596 - val_loss: 1.3105 - val_accuracy: 0.2590\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2536 - accuracy: 0.3693 - val_loss: 1.3208 - val_accuracy: 0.2590\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2491 - accuracy: 0.3660 - val_loss: 1.3203 - val_accuracy: 0.2878\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2544 - accuracy: 0.3564 - val_loss: 1.2991 - val_accuracy: 0.2446\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2490 - accuracy: 0.3717 - val_loss: 1.3086 - val_accuracy: 0.3022\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2464 - accuracy: 0.3580 - val_loss: 1.2993 - val_accuracy: 0.2518\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2472 - accuracy: 0.3862 - val_loss: 1.3166 - val_accuracy: 0.2806\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2452 - accuracy: 0.3789 - val_loss: 1.3112 - val_accuracy: 0.2590\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2408 - accuracy: 0.3741 - val_loss: 1.2967 - val_accuracy: 0.2302\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2426 - accuracy: 0.3701 - val_loss: 1.3031 - val_accuracy: 0.2734\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2415 - accuracy: 0.3813 - val_loss: 1.3160 - val_accuracy: 0.2806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2398 - accuracy: 0.3797 - val_loss: 1.3068 - val_accuracy: 0.2662\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2406 - accuracy: 0.3765 - val_loss: 1.3264 - val_accuracy: 0.2806\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2354 - accuracy: 0.3821 - val_loss: 1.3112 - val_accuracy: 0.3094\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2372 - accuracy: 0.3733 - val_loss: 1.3168 - val_accuracy: 0.2806\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2366 - accuracy: 0.3701 - val_loss: 1.3027 - val_accuracy: 0.2662\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2371 - accuracy: 0.3813 - val_loss: 1.3053 - val_accuracy: 0.2662\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2374 - accuracy: 0.3749 - val_loss: 1.3084 - val_accuracy: 0.2950\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2336 - accuracy: 0.3870 - val_loss: 1.2973 - val_accuracy: 0.2662\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2336 - accuracy: 0.3644 - val_loss: 1.3068 - val_accuracy: 0.3165\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2304 - accuracy: 0.3821 - val_loss: 1.3005 - val_accuracy: 0.2950\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2299 - accuracy: 0.3725 - val_loss: 1.3080 - val_accuracy: 0.2878\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2319 - accuracy: 0.3854 - val_loss: 1.2933 - val_accuracy: 0.2878\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2292 - accuracy: 0.3757 - val_loss: 1.3049 - val_accuracy: 0.2734\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2266 - accuracy: 0.3789 - val_loss: 1.3003 - val_accuracy: 0.2590\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2288 - accuracy: 0.3669 - val_loss: 1.3081 - val_accuracy: 0.2950\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2241 - accuracy: 0.3733 - val_loss: 1.3016 - val_accuracy: 0.2734\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2247 - accuracy: 0.3862 - val_loss: 1.2966 - val_accuracy: 0.3309\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2235 - accuracy: 0.3741 - val_loss: 1.3137 - val_accuracy: 0.2662\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2254 - accuracy: 0.3669 - val_loss: 1.2904 - val_accuracy: 0.3525\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2202 - accuracy: 0.3733 - val_loss: 1.3042 - val_accuracy: 0.2878\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2204 - accuracy: 0.3846 - val_loss: 1.2980 - val_accuracy: 0.2950\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2224 - accuracy: 0.3701 - val_loss: 1.2867 - val_accuracy: 0.2806\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2190 - accuracy: 0.3854 - val_loss: 1.2903 - val_accuracy: 0.2734\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2187 - accuracy: 0.3870 - val_loss: 1.2920 - val_accuracy: 0.2878\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2225 - accuracy: 0.3717 - val_loss: 1.2945 - val_accuracy: 0.2878\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2164 - accuracy: 0.3773 - val_loss: 1.2824 - val_accuracy: 0.2518\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2183 - accuracy: 0.3789 - val_loss: 1.2840 - val_accuracy: 0.3022\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2165 - accuracy: 0.3733 - val_loss: 1.2806 - val_accuracy: 0.2950\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2161 - accuracy: 0.3741 - val_loss: 1.2870 - val_accuracy: 0.2734\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2156 - accuracy: 0.3733 - val_loss: 1.2935 - val_accuracy: 0.2878\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2133 - accuracy: 0.3757 - val_loss: 1.2929 - val_accuracy: 0.2662\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2119 - accuracy: 0.3878 - val_loss: 1.2856 - val_accuracy: 0.2734\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2099 - accuracy: 0.3950 - val_loss: 1.2917 - val_accuracy: 0.2590\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2111 - accuracy: 0.3821 - val_loss: 1.2787 - val_accuracy: 0.2806\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2078 - accuracy: 0.3757 - val_loss: 1.2984 - val_accuracy: 0.2662\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2088 - accuracy: 0.3789 - val_loss: 1.2786 - val_accuracy: 0.2950\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2104 - accuracy: 0.3837 - val_loss: 1.2842 - val_accuracy: 0.2806\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2081 - accuracy: 0.3781 - val_loss: 1.2768 - val_accuracy: 0.2734\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2076 - accuracy: 0.3813 - val_loss: 1.2853 - val_accuracy: 0.2662\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2085 - accuracy: 0.3773 - val_loss: 1.2833 - val_accuracy: 0.3094\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2030 - accuracy: 0.3878 - val_loss: 1.2961 - val_accuracy: 0.2590\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2060 - accuracy: 0.3789 - val_loss: 1.2787 - val_accuracy: 0.2806\n",
      "11/11 [==============================] - 0s 700us/step\n",
      "F1-score: 22.68\n"
     ]
    }
   ],
   "source": [
    "# Encode the categorical features\n",
    "le = LabelEncoder()\n",
    "df_encoded = df.apply(le.fit_transform)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X_nn = df_encoded.drop('buying', axis=1)\n",
    "y_nn = df_encoded['buying']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_nn_train, X_nn_test, y_nn_train, y_nn_test = train_test_split(X_nn, y_nn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_nn_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y_nn)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(X_nn_train, keras.utils.to_categorical(y_nn_train), epochs=100, batch_size=16, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_nn_pred = model.predict(X_nn_test)\n",
    "y_nn_pred = np.argmax(y_nn_pred, axis=1)\n",
    "f1 = f1_score(y_nn_test, y_nn_pred, average='macro')\n",
    "print('F1-score: %.2f' % (f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8a95ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.23410404624277456\n",
      "f1 score is  0.22681391551669405\n"
     ]
    }
   ],
   "source": [
    "print('accuracy is ', accuracy_score(y_nn_test, y_nn_pred))\n",
    "print('f1 score is ', f1_score(y_nn_test, y_nn_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abaa555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## seems like the neural network is overfitting because the test set accuracy is much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4b0b801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "78/78 [==============================] - 1s 3ms/step - loss: 1.4847 - accuracy: 0.2663 - val_loss: 1.3930 - val_accuracy: 0.2806\n",
      "Epoch 2/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.4291 - accuracy: 0.2365 - val_loss: 1.3853 - val_accuracy: 0.2446\n",
      "Epoch 3/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.4165 - accuracy: 0.2212 - val_loss: 1.3822 - val_accuracy: 0.2950\n",
      "Epoch 4/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3902 - accuracy: 0.2550 - val_loss: 1.3839 - val_accuracy: 0.2662\n",
      "Epoch 5/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3901 - accuracy: 0.2832 - val_loss: 1.3846 - val_accuracy: 0.2374\n",
      "Epoch 6/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3906 - accuracy: 0.2582 - val_loss: 1.3833 - val_accuracy: 0.2374\n",
      "Epoch 7/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3866 - accuracy: 0.2679 - val_loss: 1.3840 - val_accuracy: 0.2662\n",
      "Epoch 8/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3884 - accuracy: 0.2751 - val_loss: 1.3830 - val_accuracy: 0.2518\n",
      "Epoch 9/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3856 - accuracy: 0.2719 - val_loss: 1.3835 - val_accuracy: 0.2518\n",
      "Epoch 10/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3888 - accuracy: 0.2526 - val_loss: 1.3854 - val_accuracy: 0.2878\n",
      "Epoch 11/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3859 - accuracy: 0.2671 - val_loss: 1.3841 - val_accuracy: 0.2662\n",
      "Epoch 12/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3899 - accuracy: 0.2494 - val_loss: 1.3829 - val_accuracy: 0.3022\n",
      "Epoch 13/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3828 - accuracy: 0.2655 - val_loss: 1.3807 - val_accuracy: 0.3022\n",
      "Epoch 14/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3850 - accuracy: 0.2663 - val_loss: 1.3793 - val_accuracy: 0.2878\n",
      "Epoch 15/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3785 - accuracy: 0.2767 - val_loss: 1.3797 - val_accuracy: 0.3094\n",
      "Epoch 16/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3768 - accuracy: 0.2743 - val_loss: 1.3780 - val_accuracy: 0.2950\n",
      "Epoch 17/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3799 - accuracy: 0.2639 - val_loss: 1.3774 - val_accuracy: 0.3381\n",
      "Epoch 18/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3828 - accuracy: 0.2743 - val_loss: 1.3745 - val_accuracy: 0.3094\n",
      "Epoch 19/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3790 - accuracy: 0.2759 - val_loss: 1.3718 - val_accuracy: 0.3022\n",
      "Epoch 20/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3787 - accuracy: 0.2607 - val_loss: 1.3697 - val_accuracy: 0.2662\n",
      "Epoch 21/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3794 - accuracy: 0.2711 - val_loss: 1.3724 - val_accuracy: 0.2806\n",
      "Epoch 22/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3735 - accuracy: 0.2872 - val_loss: 1.3615 - val_accuracy: 0.3022\n",
      "Epoch 23/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3770 - accuracy: 0.2840 - val_loss: 1.3621 - val_accuracy: 0.2806\n",
      "Epoch 24/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3743 - accuracy: 0.2904 - val_loss: 1.3605 - val_accuracy: 0.2734\n",
      "Epoch 25/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3721 - accuracy: 0.2840 - val_loss: 1.3655 - val_accuracy: 0.3022\n",
      "Epoch 26/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3677 - accuracy: 0.2800 - val_loss: 1.3611 - val_accuracy: 0.2662\n",
      "Epoch 27/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3693 - accuracy: 0.2872 - val_loss: 1.3593 - val_accuracy: 0.2878\n",
      "Epoch 28/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3716 - accuracy: 0.2792 - val_loss: 1.3604 - val_accuracy: 0.2662\n",
      "Epoch 29/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3660 - accuracy: 0.2880 - val_loss: 1.3553 - val_accuracy: 0.2734\n",
      "Epoch 30/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3618 - accuracy: 0.2920 - val_loss: 1.3558 - val_accuracy: 0.2734\n",
      "Epoch 31/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3729 - accuracy: 0.2824 - val_loss: 1.3510 - val_accuracy: 0.2806\n",
      "Epoch 32/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3655 - accuracy: 0.2864 - val_loss: 1.3535 - val_accuracy: 0.2878\n",
      "Epoch 33/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3633 - accuracy: 0.2776 - val_loss: 1.3543 - val_accuracy: 0.2662\n",
      "Epoch 34/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3667 - accuracy: 0.3017 - val_loss: 1.3544 - val_accuracy: 0.2662\n",
      "Epoch 35/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3628 - accuracy: 0.2751 - val_loss: 1.3573 - val_accuracy: 0.2806\n",
      "Epoch 36/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3556 - accuracy: 0.2961 - val_loss: 1.3562 - val_accuracy: 0.2734\n",
      "Epoch 37/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3566 - accuracy: 0.2977 - val_loss: 1.3516 - val_accuracy: 0.2806\n",
      "Epoch 38/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3522 - accuracy: 0.3001 - val_loss: 1.3507 - val_accuracy: 0.2806\n",
      "Epoch 39/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3541 - accuracy: 0.3105 - val_loss: 1.3509 - val_accuracy: 0.2806\n",
      "Epoch 40/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3547 - accuracy: 0.3049 - val_loss: 1.3503 - val_accuracy: 0.2878\n",
      "Epoch 41/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3602 - accuracy: 0.2969 - val_loss: 1.3508 - val_accuracy: 0.3165\n",
      "Epoch 42/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3541 - accuracy: 0.2969 - val_loss: 1.3513 - val_accuracy: 0.2950\n",
      "Epoch 43/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3486 - accuracy: 0.3146 - val_loss: 1.3429 - val_accuracy: 0.2878\n",
      "Epoch 44/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3529 - accuracy: 0.2936 - val_loss: 1.3405 - val_accuracy: 0.3094\n",
      "Epoch 45/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3411 - accuracy: 0.3186 - val_loss: 1.3354 - val_accuracy: 0.2950\n",
      "Epoch 46/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3411 - accuracy: 0.3274 - val_loss: 1.3327 - val_accuracy: 0.2734\n",
      "Epoch 47/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3452 - accuracy: 0.3025 - val_loss: 1.3379 - val_accuracy: 0.2806\n",
      "Epoch 48/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3436 - accuracy: 0.3017 - val_loss: 1.3345 - val_accuracy: 0.2662\n",
      "Epoch 49/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3498 - accuracy: 0.3001 - val_loss: 1.3350 - val_accuracy: 0.2878\n",
      "Epoch 50/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3469 - accuracy: 0.2985 - val_loss: 1.3335 - val_accuracy: 0.2806\n",
      "Epoch 51/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3341 - accuracy: 0.3282 - val_loss: 1.3340 - val_accuracy: 0.2590\n",
      "Epoch 52/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3525 - accuracy: 0.2961 - val_loss: 1.3311 - val_accuracy: 0.3022\n",
      "Epoch 53/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3402 - accuracy: 0.3113 - val_loss: 1.3320 - val_accuracy: 0.3165\n",
      "Epoch 54/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3439 - accuracy: 0.3105 - val_loss: 1.3302 - val_accuracy: 0.3022\n",
      "Epoch 55/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3431 - accuracy: 0.2880 - val_loss: 1.3243 - val_accuracy: 0.3094\n",
      "Epoch 56/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3268 - accuracy: 0.3025 - val_loss: 1.3217 - val_accuracy: 0.2950\n",
      "Epoch 57/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3387 - accuracy: 0.3162 - val_loss: 1.3224 - val_accuracy: 0.3165\n",
      "Epoch 58/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3325 - accuracy: 0.3138 - val_loss: 1.3214 - val_accuracy: 0.2950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3367 - accuracy: 0.3162 - val_loss: 1.3230 - val_accuracy: 0.2806\n",
      "Epoch 60/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3249 - accuracy: 0.3138 - val_loss: 1.3204 - val_accuracy: 0.2662\n",
      "Epoch 61/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3274 - accuracy: 0.3025 - val_loss: 1.3227 - val_accuracy: 0.2662\n",
      "Epoch 62/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3296 - accuracy: 0.3250 - val_loss: 1.3273 - val_accuracy: 0.2590\n",
      "Epoch 63/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3281 - accuracy: 0.3073 - val_loss: 1.3237 - val_accuracy: 0.2662\n",
      "Epoch 64/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3316 - accuracy: 0.3105 - val_loss: 1.3261 - val_accuracy: 0.2734\n",
      "Epoch 65/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3420 - accuracy: 0.3081 - val_loss: 1.3244 - val_accuracy: 0.2662\n",
      "Epoch 66/300\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 1.3286 - accuracy: 0.3097 - val_loss: 1.3145 - val_accuracy: 0.2590\n",
      "Epoch 67/300\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 1.3300 - accuracy: 0.3113 - val_loss: 1.3186 - val_accuracy: 0.2590\n",
      "Epoch 68/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3143 - accuracy: 0.2936 - val_loss: 1.3110 - val_accuracy: 0.2734\n",
      "Epoch 69/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3233 - accuracy: 0.3154 - val_loss: 1.3153 - val_accuracy: 0.2734\n",
      "Epoch 70/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3316 - accuracy: 0.2896 - val_loss: 1.3126 - val_accuracy: 0.2662\n",
      "Epoch 71/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3246 - accuracy: 0.3057 - val_loss: 1.3111 - val_accuracy: 0.2518\n",
      "Epoch 72/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3230 - accuracy: 0.3266 - val_loss: 1.3062 - val_accuracy: 0.2446\n",
      "Epoch 73/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3155 - accuracy: 0.3146 - val_loss: 1.3082 - val_accuracy: 0.2374\n",
      "Epoch 74/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3150 - accuracy: 0.3146 - val_loss: 1.3095 - val_accuracy: 0.2446\n",
      "Epoch 75/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3225 - accuracy: 0.3017 - val_loss: 1.3042 - val_accuracy: 0.2446\n",
      "Epoch 76/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3139 - accuracy: 0.3347 - val_loss: 1.3019 - val_accuracy: 0.2590\n",
      "Epoch 77/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3154 - accuracy: 0.3234 - val_loss: 1.3027 - val_accuracy: 0.2518\n",
      "Epoch 78/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3087 - accuracy: 0.3130 - val_loss: 1.2981 - val_accuracy: 0.2590\n",
      "Epoch 79/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3105 - accuracy: 0.3186 - val_loss: 1.2942 - val_accuracy: 0.2662\n",
      "Epoch 80/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2996 - accuracy: 0.3323 - val_loss: 1.3036 - val_accuracy: 0.2446\n",
      "Epoch 81/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3155 - accuracy: 0.3194 - val_loss: 1.2931 - val_accuracy: 0.2446\n",
      "Epoch 82/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3110 - accuracy: 0.3178 - val_loss: 1.2928 - val_accuracy: 0.2518\n",
      "Epoch 83/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3069 - accuracy: 0.3154 - val_loss: 1.2939 - val_accuracy: 0.2374\n",
      "Epoch 84/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3073 - accuracy: 0.3138 - val_loss: 1.2876 - val_accuracy: 0.2734\n",
      "Epoch 85/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3114 - accuracy: 0.3138 - val_loss: 1.2843 - val_accuracy: 0.2446\n",
      "Epoch 86/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3110 - accuracy: 0.3033 - val_loss: 1.2873 - val_accuracy: 0.2878\n",
      "Epoch 87/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3073 - accuracy: 0.3065 - val_loss: 1.2854 - val_accuracy: 0.2734\n",
      "Epoch 88/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3024 - accuracy: 0.3379 - val_loss: 1.2884 - val_accuracy: 0.2518\n",
      "Epoch 89/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2948 - accuracy: 0.3379 - val_loss: 1.2877 - val_accuracy: 0.2662\n",
      "Epoch 90/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3041 - accuracy: 0.3218 - val_loss: 1.2817 - val_accuracy: 0.2662\n",
      "Epoch 91/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2954 - accuracy: 0.3081 - val_loss: 1.2803 - val_accuracy: 0.2302\n",
      "Epoch 92/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2957 - accuracy: 0.3138 - val_loss: 1.2822 - val_accuracy: 0.2590\n",
      "Epoch 93/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2943 - accuracy: 0.3282 - val_loss: 1.2827 - val_accuracy: 0.2518\n",
      "Epoch 94/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3104 - accuracy: 0.3001 - val_loss: 1.2750 - val_accuracy: 0.2662\n",
      "Epoch 95/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.3031 - accuracy: 0.3121 - val_loss: 1.2806 - val_accuracy: 0.2446\n",
      "Epoch 96/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2989 - accuracy: 0.3154 - val_loss: 1.2753 - val_accuracy: 0.2590\n",
      "Epoch 97/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2949 - accuracy: 0.3266 - val_loss: 1.2832 - val_accuracy: 0.2806\n",
      "Epoch 98/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2879 - accuracy: 0.3403 - val_loss: 1.2788 - val_accuracy: 0.2950\n",
      "Epoch 99/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2915 - accuracy: 0.3250 - val_loss: 1.2815 - val_accuracy: 0.2662\n",
      "Epoch 100/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2887 - accuracy: 0.3242 - val_loss: 1.2742 - val_accuracy: 0.2590\n",
      "Epoch 101/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2981 - accuracy: 0.3250 - val_loss: 1.2670 - val_accuracy: 0.2446\n",
      "Epoch 102/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2995 - accuracy: 0.3339 - val_loss: 1.2674 - val_accuracy: 0.2590\n",
      "Epoch 103/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2882 - accuracy: 0.3347 - val_loss: 1.2756 - val_accuracy: 0.2806\n",
      "Epoch 104/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2978 - accuracy: 0.3146 - val_loss: 1.2788 - val_accuracy: 0.2734\n",
      "Epoch 105/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2879 - accuracy: 0.3121 - val_loss: 1.2666 - val_accuracy: 0.2590\n",
      "Epoch 106/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2844 - accuracy: 0.3258 - val_loss: 1.2668 - val_accuracy: 0.2662\n",
      "Epoch 107/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2817 - accuracy: 0.3210 - val_loss: 1.2659 - val_accuracy: 0.2734\n",
      "Epoch 108/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2966 - accuracy: 0.3009 - val_loss: 1.2681 - val_accuracy: 0.2446\n",
      "Epoch 109/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2886 - accuracy: 0.3210 - val_loss: 1.2716 - val_accuracy: 0.2950\n",
      "Epoch 110/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2858 - accuracy: 0.3178 - val_loss: 1.2653 - val_accuracy: 0.2878\n",
      "Epoch 111/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2951 - accuracy: 0.3242 - val_loss: 1.2654 - val_accuracy: 0.2806\n",
      "Epoch 112/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2867 - accuracy: 0.3274 - val_loss: 1.2539 - val_accuracy: 0.2878\n",
      "Epoch 113/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2873 - accuracy: 0.3403 - val_loss: 1.2576 - val_accuracy: 0.2806\n",
      "Epoch 114/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2730 - accuracy: 0.3339 - val_loss: 1.2540 - val_accuracy: 0.3094\n",
      "Epoch 115/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2885 - accuracy: 0.3218 - val_loss: 1.2488 - val_accuracy: 0.2950\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2859 - accuracy: 0.3138 - val_loss: 1.2507 - val_accuracy: 0.2734\n",
      "Epoch 117/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2772 - accuracy: 0.3315 - val_loss: 1.2440 - val_accuracy: 0.3165\n",
      "Epoch 118/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2918 - accuracy: 0.3073 - val_loss: 1.2490 - val_accuracy: 0.2950\n",
      "Epoch 119/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2924 - accuracy: 0.3017 - val_loss: 1.2579 - val_accuracy: 0.2950\n",
      "Epoch 120/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2830 - accuracy: 0.3379 - val_loss: 1.2499 - val_accuracy: 0.3094\n",
      "Epoch 121/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2780 - accuracy: 0.3210 - val_loss: 1.2503 - val_accuracy: 0.3022\n",
      "Epoch 122/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2810 - accuracy: 0.3347 - val_loss: 1.2483 - val_accuracy: 0.3165\n",
      "Epoch 123/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2752 - accuracy: 0.3298 - val_loss: 1.2446 - val_accuracy: 0.3237\n",
      "Epoch 124/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2733 - accuracy: 0.3556 - val_loss: 1.2402 - val_accuracy: 0.2950\n",
      "Epoch 125/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2773 - accuracy: 0.3379 - val_loss: 1.2403 - val_accuracy: 0.3237\n",
      "Epoch 126/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2755 - accuracy: 0.3484 - val_loss: 1.2396 - val_accuracy: 0.3165\n",
      "Epoch 127/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2819 - accuracy: 0.3242 - val_loss: 1.2462 - val_accuracy: 0.2950\n",
      "Epoch 128/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2731 - accuracy: 0.3403 - val_loss: 1.2338 - val_accuracy: 0.2878\n",
      "Epoch 129/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2706 - accuracy: 0.3218 - val_loss: 1.2327 - val_accuracy: 0.3094\n",
      "Epoch 130/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2701 - accuracy: 0.3387 - val_loss: 1.2408 - val_accuracy: 0.2878\n",
      "Epoch 131/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2714 - accuracy: 0.3403 - val_loss: 1.2430 - val_accuracy: 0.3022\n",
      "Epoch 132/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2772 - accuracy: 0.3234 - val_loss: 1.2305 - val_accuracy: 0.3022\n",
      "Epoch 133/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2815 - accuracy: 0.3371 - val_loss: 1.2358 - val_accuracy: 0.3237\n",
      "Epoch 134/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2717 - accuracy: 0.3371 - val_loss: 1.2352 - val_accuracy: 0.3094\n",
      "Epoch 135/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2618 - accuracy: 0.3419 - val_loss: 1.2367 - val_accuracy: 0.2878\n",
      "Epoch 136/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2726 - accuracy: 0.3379 - val_loss: 1.2375 - val_accuracy: 0.3237\n",
      "Epoch 137/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2670 - accuracy: 0.3178 - val_loss: 1.2306 - val_accuracy: 0.2662\n",
      "Epoch 138/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2762 - accuracy: 0.3298 - val_loss: 1.2366 - val_accuracy: 0.3022\n",
      "Epoch 139/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2663 - accuracy: 0.3484 - val_loss: 1.2312 - val_accuracy: 0.3022\n",
      "Epoch 140/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2727 - accuracy: 0.3226 - val_loss: 1.2369 - val_accuracy: 0.3237\n",
      "Epoch 141/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2626 - accuracy: 0.3411 - val_loss: 1.2276 - val_accuracy: 0.2806\n",
      "Epoch 142/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2588 - accuracy: 0.3387 - val_loss: 1.2297 - val_accuracy: 0.3237\n",
      "Epoch 143/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2630 - accuracy: 0.3459 - val_loss: 1.2301 - val_accuracy: 0.3309\n",
      "Epoch 144/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2803 - accuracy: 0.3202 - val_loss: 1.2283 - val_accuracy: 0.3237\n",
      "Epoch 145/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2605 - accuracy: 0.3451 - val_loss: 1.2246 - val_accuracy: 0.3165\n",
      "Epoch 146/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2624 - accuracy: 0.3363 - val_loss: 1.2190 - val_accuracy: 0.3022\n",
      "Epoch 147/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2652 - accuracy: 0.3484 - val_loss: 1.2195 - val_accuracy: 0.2950\n",
      "Epoch 148/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2551 - accuracy: 0.3620 - val_loss: 1.2257 - val_accuracy: 0.3094\n",
      "Epoch 149/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2666 - accuracy: 0.3411 - val_loss: 1.2311 - val_accuracy: 0.3237\n",
      "Epoch 150/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2760 - accuracy: 0.3266 - val_loss: 1.2282 - val_accuracy: 0.2950\n",
      "Epoch 151/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2652 - accuracy: 0.3548 - val_loss: 1.2217 - val_accuracy: 0.3022\n",
      "Epoch 152/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2649 - accuracy: 0.3588 - val_loss: 1.2311 - val_accuracy: 0.3237\n",
      "Epoch 153/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2589 - accuracy: 0.3500 - val_loss: 1.2246 - val_accuracy: 0.2950\n",
      "Epoch 154/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2648 - accuracy: 0.3331 - val_loss: 1.2240 - val_accuracy: 0.3094\n",
      "Epoch 155/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2596 - accuracy: 0.3355 - val_loss: 1.2158 - val_accuracy: 0.2878\n",
      "Epoch 156/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2612 - accuracy: 0.3387 - val_loss: 1.2158 - val_accuracy: 0.3309\n",
      "Epoch 157/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2699 - accuracy: 0.3467 - val_loss: 1.2134 - val_accuracy: 0.3165\n",
      "Epoch 158/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2661 - accuracy: 0.3492 - val_loss: 1.2168 - val_accuracy: 0.3165\n",
      "Epoch 159/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2617 - accuracy: 0.3419 - val_loss: 1.2184 - val_accuracy: 0.3022\n",
      "Epoch 160/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2609 - accuracy: 0.3564 - val_loss: 1.2252 - val_accuracy: 0.2950\n",
      "Epoch 161/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2580 - accuracy: 0.3355 - val_loss: 1.2182 - val_accuracy: 0.3094\n",
      "Epoch 162/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2561 - accuracy: 0.3323 - val_loss: 1.2174 - val_accuracy: 0.3022\n",
      "Epoch 163/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2624 - accuracy: 0.3339 - val_loss: 1.2171 - val_accuracy: 0.3165\n",
      "Epoch 164/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2535 - accuracy: 0.3484 - val_loss: 1.2114 - val_accuracy: 0.3309\n",
      "Epoch 165/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2636 - accuracy: 0.3234 - val_loss: 1.2107 - val_accuracy: 0.3309\n",
      "Epoch 166/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2404 - accuracy: 0.3548 - val_loss: 1.2193 - val_accuracy: 0.3022\n",
      "Epoch 167/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2689 - accuracy: 0.3451 - val_loss: 1.2174 - val_accuracy: 0.2878\n",
      "Epoch 168/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2531 - accuracy: 0.3725 - val_loss: 1.2085 - val_accuracy: 0.3165\n",
      "Epoch 169/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2460 - accuracy: 0.3548 - val_loss: 1.2061 - val_accuracy: 0.3022\n",
      "Epoch 170/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2709 - accuracy: 0.3146 - val_loss: 1.2109 - val_accuracy: 0.2806\n",
      "Epoch 171/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2616 - accuracy: 0.3484 - val_loss: 1.2299 - val_accuracy: 0.3022\n",
      "Epoch 172/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2512 - accuracy: 0.3580 - val_loss: 1.2125 - val_accuracy: 0.2878\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2543 - accuracy: 0.3556 - val_loss: 1.2148 - val_accuracy: 0.2950\n",
      "Epoch 174/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2551 - accuracy: 0.3580 - val_loss: 1.2093 - val_accuracy: 0.2734\n",
      "Epoch 175/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2631 - accuracy: 0.3435 - val_loss: 1.2183 - val_accuracy: 0.2950\n",
      "Epoch 176/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2452 - accuracy: 0.3484 - val_loss: 1.2128 - val_accuracy: 0.3094\n",
      "Epoch 177/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2547 - accuracy: 0.3500 - val_loss: 1.2054 - val_accuracy: 0.3022\n",
      "Epoch 178/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2460 - accuracy: 0.3612 - val_loss: 1.2046 - val_accuracy: 0.3022\n",
      "Epoch 179/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2560 - accuracy: 0.3548 - val_loss: 1.2143 - val_accuracy: 0.2878\n",
      "Epoch 180/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2728 - accuracy: 0.3451 - val_loss: 1.2076 - val_accuracy: 0.3022\n",
      "Epoch 181/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2565 - accuracy: 0.3540 - val_loss: 1.2019 - val_accuracy: 0.3022\n",
      "Epoch 182/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2486 - accuracy: 0.3556 - val_loss: 1.2000 - val_accuracy: 0.3094\n",
      "Epoch 183/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2569 - accuracy: 0.3459 - val_loss: 1.1987 - val_accuracy: 0.2950\n",
      "Epoch 184/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2532 - accuracy: 0.3709 - val_loss: 1.2042 - val_accuracy: 0.3309\n",
      "Epoch 185/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2495 - accuracy: 0.3459 - val_loss: 1.2026 - val_accuracy: 0.3165\n",
      "Epoch 186/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2406 - accuracy: 0.3628 - val_loss: 1.1958 - val_accuracy: 0.3165\n",
      "Epoch 187/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2465 - accuracy: 0.3484 - val_loss: 1.1989 - val_accuracy: 0.3022\n",
      "Epoch 188/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2478 - accuracy: 0.3660 - val_loss: 1.1927 - val_accuracy: 0.2878\n",
      "Epoch 189/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2439 - accuracy: 0.3596 - val_loss: 1.1981 - val_accuracy: 0.3022\n",
      "Epoch 190/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2533 - accuracy: 0.3443 - val_loss: 1.2005 - val_accuracy: 0.2734\n",
      "Epoch 191/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2483 - accuracy: 0.3556 - val_loss: 1.1995 - val_accuracy: 0.3022\n",
      "Epoch 192/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2369 - accuracy: 0.3644 - val_loss: 1.2025 - val_accuracy: 0.2734\n",
      "Epoch 193/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2500 - accuracy: 0.3516 - val_loss: 1.1966 - val_accuracy: 0.2950\n",
      "Epoch 194/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2347 - accuracy: 0.3588 - val_loss: 1.2008 - val_accuracy: 0.2662\n",
      "Epoch 195/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2427 - accuracy: 0.3660 - val_loss: 1.1940 - val_accuracy: 0.2878\n",
      "Epoch 196/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2324 - accuracy: 0.3677 - val_loss: 1.1943 - val_accuracy: 0.2950\n",
      "Epoch 197/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2481 - accuracy: 0.3395 - val_loss: 1.1955 - val_accuracy: 0.3022\n",
      "Epoch 198/300\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 1.2450 - accuracy: 0.3540 - val_loss: 1.2022 - val_accuracy: 0.2950\n",
      "11/11 [==============================] - 0s 700us/step\n",
      "accuracy is  0.2774566473988439\n",
      "f1 score is  0.25993491479990294\n"
     ]
    }
   ],
   "source": [
    "## seems like the neural network is overfitting because the test set accuracy is much lower.\n",
    "## add dropout, regularization and early stoppage\n",
    "\n",
    "\n",
    "# Encode the categorical features\n",
    "le = LabelEncoder()\n",
    "df_encoded = df.apply(le.fit_transform)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X_nn = df_encoded.drop('buying', axis=1)\n",
    "y_nn = df_encoded['buying']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_nn_train, X_nn_test, y_nn_train, y_nn_test = train_test_split(X_nn, y_nn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_nn_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(np.unique(y_nn)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(X_nn_train, keras.utils.to_categorical(y_nn_train), epochs=300, batch_size=16, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_nn_pred = model.predict(X_nn_test)\n",
    "y_nn_pred = np.argmax(y_nn_pred, axis=1)\n",
    "\n",
    "print('accuracy is ', accuracy_score(y_nn_test, y_nn_pred))\n",
    "print('f1 score is ', f1_score(y_nn_test, y_nn_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765041bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: SVC still performs better than neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67731b",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e49cd5e",
   "metadata": {},
   "source": [
    "## Input Parameters\n",
    "- Maintenance = High\n",
    "- Number of doors = 4\n",
    "- Lug Boot Size = Big\n",
    "- Safety = High\n",
    "- Class Value = Good\n",
    "\n",
    "Since SVC was found to be the best performing model, I will use SVC to make the prediction.\n",
    "\n",
    "Unfortunately, 'persons' is not specified, which is currently a feature used in the model. \n",
    "\n",
    "There are 2 options to handle this:\n",
    "1. re-train the model but without using persons as a feature\n",
    "2. assume a value for persons (realistically, i would assume that persons is 'more' since there are 4 doors. however, the data is synthetic and there is no correlation between doors and persons\n",
    "\n",
    "I will assume various values of persons to see if the prediction changes. if there is no change then we can assume that 'persons' does not impact the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97683878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming persons is 'more'\n",
    "\n",
    "input_data = {'maint_low':0,\n",
    "              'maint_med':0,\n",
    "              'maint_vhigh':0,\n",
    "              'doors_3':0,\n",
    "              'doors_4':1,\n",
    "              'doors_5more':0,\n",
    "              'persons_4':0,\n",
    "              'persons_more':1,\n",
    "              'lug_boot_med':0,\n",
    "              'lug_boot_small':0,\n",
    "              'safety_low':0,\n",
    "              'safety_med':0,\n",
    "              'class_good':1,\n",
    "              'class_unacc':0,\n",
    "              'class_vgood':0}\n",
    "input_df = pd.DataFrame(input_data, index=[0])\n",
    "best_model_cat.predict(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a246636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming persons is '4'\n",
    "\n",
    "input_data = {'maint_low':0,\n",
    "              'maint_med':0,\n",
    "              'maint_vhigh':0,\n",
    "              'doors_3':0,\n",
    "              'doors_4':1,\n",
    "              'doors_5more':0,\n",
    "              'persons_4':1,\n",
    "              'persons_more':0,\n",
    "              'lug_boot_med':0,\n",
    "              'lug_boot_small':0,\n",
    "              'safety_low':0,\n",
    "              'safety_med':0,\n",
    "              'class_good':1,\n",
    "              'class_unacc':0,\n",
    "              'class_vgood':0}\n",
    "input_df = pd.DataFrame(input_data, index=[0])\n",
    "best_model_cat.predict(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7efdf1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming persons is '2'\n",
    "\n",
    "input_data = {'maint_low':0,\n",
    "              'maint_med':0,\n",
    "              'maint_vhigh':0,\n",
    "              'doors_3':0,\n",
    "              'doors_4':1,\n",
    "              'doors_5more':0,\n",
    "              'persons_4':0,\n",
    "              'persons_more':0,\n",
    "              'lug_boot_med':0,\n",
    "              'lug_boot_small':0,\n",
    "              'safety_low':0,\n",
    "              'safety_med':0,\n",
    "              'class_good':1,\n",
    "              'class_unacc':0,\n",
    "              'class_vgood':0}\n",
    "input_df = pd.DataFrame(input_data, index=[0])\n",
    "best_model_cat.predict(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb80de",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Regardless of the value of 'persons', the prediction for buying is still 'low'. \n",
    "\n",
    "Hence, based on this model, the prediction for 'buying' is 'low'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9869c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
